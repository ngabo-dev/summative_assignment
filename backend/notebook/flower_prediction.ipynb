{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Classification ML Model\n",
    "\n",
    "This notebook contains the complete workflow for training and evaluating a flower classification model.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Exploration](#data-exploration)\n",
    "2. [Data Preprocessing](#data-preprocessing)\n",
    "3. [Model Architecture](#model-architecture)\n",
    "4. [Training](#training)\n",
    "5. [Evaluation](#evaluation)\n",
    "6. [Visualization](#visualization)\n",
    "7. [Model Export](#model-export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path for importing our modules\n",
    "sys.path.append('../src')\n",
    "from preprocessing import DataPreprocessor\n",
    "from model import ModelManager\n",
    "from prediction import FlowerPredictor\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data preprocessor\n",
    "preprocessor = DataPreprocessor(data_dir='../data')\n",
    "\n",
    "# Get dataset statistics\n",
    "stats = preprocessor.get_dataset_statistics()\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total images: {stats['total_images']}\")\n",
    "print(f\"Training images: {stats['train_images']}\")\n",
    "print(f\"Test images: {stats['test_images']}\")\n",
    "print(f\"Dataset health: {stats['dataset_health']}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "for class_name, counts in stats['class_distribution'].items():\n",
    "    print(f\"  {class_name}: {counts['total']} total ({counts['train']} train, {counts['test']} test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "class_names = list(stats['class_distribution'].keys())\n",
    "class_counts = [stats['class_distribution'][name]['total'] for name in class_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(class_names, class_counts, color=['#ff7f7f', '#7f7fff', '#ffff7f'])\n",
    "plt.title('Class Distribution (Total Images)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(class_counts, labels=class_names, autopct='%1.1f%%', colors=['#ff7f7f', '#7f7fff', '#ffff7f'])\n",
    "plt.title('Class Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "def show_sample_images(data_dir, class_names, samples_per_class=3):\n",
    "    fig, axes = plt.subplots(len(class_names), samples_per_class, figsize=(15, 12))\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, 'train', class_name)\n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        for j in range(min(samples_per_class, len(images))):\n",
    "            img_path = os.path.join(class_dir, images[j])\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].set_title(f'{class_name.capitalize()} - {images[j]}')\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images('../data', class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up corrupted images\n",
    "preprocessor.cleanup_dataset()\n",
    "\n",
    "# Create data generators\n",
    "train_generator, validation_generator, test_generator = preprocessor.create_data_generators(batch_size=32)\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "def show_augmented_images(generator, num_images=8):\n",
    "    batch_images, batch_labels = next(generator)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(min(num_images, len(batch_images))):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(batch_images[i])\n",
    "        \n",
    "        # Get class name from label\n",
    "        class_idx = np.argmax(batch_labels[i])\n",
    "        class_name = list(train_generator.class_indices.keys())[class_idx]\n",
    "        plt.title(f'Class: {class_name}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Augmented Training Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_augmented_images(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN model\n",
    "def create_custom_cnn(input_shape=(224, 224, 3), num_classes=3):\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_custom_cnn()\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning with VGG16\n",
    "def create_transfer_learning_model(base_model_name='VGG16', input_shape=(224, 224, 3), num_classes=3):\n",
    "    # Load pre-trained base model\n",
    "    if base_model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'InceptionV3':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create transfer learning model\n",
    "transfer_model = create_transfer_learning_model('VGG16')\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Transfer Learning Model Summary:\")\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        '../models/best_model.tf',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the custom CNN model\n",
    "print(\"Training Custom CNN Model...\")\n",
    "history_cnn = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train transfer learning model\n",
    "print(\"Training Transfer Learning Model...\")\n",
    "callbacks_transfer = [\n",
    "    ModelCheckpoint(\n",
    "        '../models/best_transfer_model.tf',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history_transfer = transfer_model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_transfer,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history, title=\"Model Training History\"):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot learning rate (if available)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'lr' in history.history:\n",
    "        plt.plot(history.history['lr'], label='Learning Rate')\n",
    "        plt.title('Learning Rate')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Learning Rate\\nNot Recorded', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training histories\n",
    "plot_training_history(history_cnn, \"Custom CNN Training History\")\n",
    "plot_training_history(history_transfer, \"Transfer Learning Training History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on validation data\n",
    "def evaluate_model(model, validation_generator, model_name):\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Reset generator\n",
    "    validation_generator.reset()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(validation_generator, verbose=1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = validation_generator.classes[:len(predicted_classes)]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    class_names = list(validation_generator.class_indices.keys())\n",
    "    report = classification_report(true_classes, predicted_classes, \n",
    "                                 target_names=class_names, output_dict=True)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return report, accuracy\n",
    "\n",
    "# Evaluate both models\n",
    "cnn_report, cnn_accuracy = evaluate_model(model, validation_generator, \"Custom CNN\")\n",
    "transfer_report, transfer_accuracy = evaluate_model(transfer_model, validation_generator, \"Transfer Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "def compare_models(cnn_report, transfer_report, cnn_acc, transfer_acc):\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    classes = ['rose', 'tulip', 'sunflower']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        cnn_scores = [cnn_report[cls][metric] for cls in classes]\n",
    "        transfer_scores = [transfer_report[cls][metric] for cls in classes]\n",
    "        \n",
    "        x = np.arange(len(classes))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[i].bar(x - width/2, cnn_scores, width, label='Custom CNN', alpha=0.8)\n",
    "        axes[i].bar(x + width/2, transfer_scores, width, label='Transfer Learning', alpha=0.8)\n",
    "        \n",
    "        axes[i].set_xlabel('Classes')\n",
    "        axes[i].set_ylabel(metric.capitalize())\n",
    "        axes[i].set_title(f'{metric.capitalize()} Comparison')\n",
    "        axes[i].set_xticks(x)\n",
    "        axes[i].set_xticklabels(classes)\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nModel Comparison Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Custom CNN Accuracy: {cnn_acc:.4f}\")\n",
    "    print(f\"Transfer Learning Accuracy: {transfer_acc:.4f}\")\n",
    "    print(f\"Best Model: {'Transfer Learning' if transfer_acc > cnn_acc else 'Custom CNN'}\")\n",
    "\n",
    "compare_models(cnn_report, transfer_report, cnn_accuracy, transfer_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on sample images\n",
    "def visualize_predictions(model, validation_generator, num_samples=9):\n",
    "    validation_generator.reset()\n",
    "    batch_images, batch_labels = next(validation_generator)\n",
    "    \n",
    "    predictions = model.predict(batch_images[:num_samples])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(batch_labels[:num_samples], axis=1)\n",
    "    \n",
    "    class_names = list(validation_generator.class_indices.keys())\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(batch_images[i])\n",
    "        \n",
    "        true_class = class_names[true_classes[i]]\n",
    "        pred_class = class_names[predicted_classes[i]]\n",
    "        confidence = predictions[i][predicted_classes[i]] * 100\n",
    "        \n",
    "        color = 'green' if true_classes[i] == predicted_classes[i] else 'red'\n",
    "        \n",
    "        plt.title(f'True: {true_class}\\nPred: {pred_class}\\nConf: {confidence:.1f}%', \n",
    "                 color=color, fontsize=12)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions on Validation Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions for both models\n",
    "print(\"Custom CNN Predictions:\")\n",
    "visualize_predictions(model, validation_generator)\n",
    "\n",
    "print(\"\\nTransfer Learning Predictions:\")\n",
    "visualize_predictions(transfer_model, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature visualization - Conv layer activations\n",
    "def visualize_conv_layers(model, sample_image, layer_names=None):\n",
    "    if layer_names is None:\n",
    "        # Get first few conv layers\n",
    "        layer_names = [layer.name for layer in model.layers if 'conv' in layer.name.lower()][:4]\n",
    "    \n",
    "    # Create models that output activations\n",
    "    activation_models = [Model(inputs=model.input, outputs=model.get_layer(name).output) \n",
    "                        for name in layer_names]\n",
    "    \n",
    "    # Get activations\n",
    "    activations = [activation_model.predict(np.expand_dims(sample_image, axis=0)) \n",
    "                  for activation_model in activation_models]\n",
    "    \n",
    "    # Plot activations\n",
    "    fig, axes = plt.subplots(len(layer_names), 8, figsize=(20, len(layer_names) * 3))\n",
    "    \n",
    "    for i, (layer_name, activation) in enumerate(zip(layer_names, activations)):\n",
    "        # Show first 8 feature maps\n",
    "        for j in range(min(8, activation.shape[-1])):\n",
    "            if len(layer_names) == 1:\n",
    "                ax = axes[j]\n",
    "            else:\n",
    "                ax = axes[i, j]\n",
    "            \n",
    "            ax.imshow(activation[0, :, :, j], cmap='viridis')\n",
    "            ax.set_title(f'{layer_name}\\nFeature {j+1}')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a sample image\n",
    "validation_generator.reset()\n",
    "sample_batch, _ = next(validation_generator)\n",
    "sample_image = sample_batch[0]\n",
    "\n",
    "print(\"Conv Layer Activations for Custom CNN:\")\n",
    "visualize_conv_layers(model, sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best performing model\n",
    "best_model = transfer_model if transfer_accuracy > cnn_accuracy else model\n",
    "best_model_name = \"transfer_learning\" if transfer_accuracy > cnn_accuracy else \"custom_cnn\"\n",
    "\n",
    "# Save in TensorFlow format\n",
    "best_model.save(f'../models/best_flower_model_{best_model_name}.tf')\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'accuracy': float(max(transfer_accuracy, cnn_accuracy)),\n",
    "    'precision': float(transfer_report['macro avg']['precision'] if transfer_accuracy > cnn_accuracy \n",
    "                     else cnn_report['macro avg']['precision']),\n",
    "    'recall': float(transfer_report['macro avg']['recall'] if transfer_accuracy > cnn_accuracy \n",
    "                   else cnn_report['macro avg']['recall']),\n",
    "    'f1_score': float(transfer_report['macro avg']['f1-score'] if transfer_accuracy > cnn_accuracy \n",
    "                     else cnn_report['macro avg']['f1-score']),\n",
    "    'class_names': ['rose', 'tulip', 'sunflower'],\n",
    "    'input_shape': [224, 224, 3],\n",
    "    'training_date': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f'../models/model_metadata_{best_model_name}.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Best model saved: {best_model_name}\")\n",
    "print(f\"Model accuracy: {metadata['accuracy']:.4f}\")\n",
    "print(f\"Metadata saved to: model_metadata_{best_model_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved model\n",
    "print(\"Testing saved model...\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model(f'../models/best_flower_model_{best_model_name}.tf')\n",
    "\n",
    "# Test prediction\n",
    "test_image = sample_batch[0:1]\n",
    "prediction = loaded_model.predict(test_image)\n",
    "predicted_class = np.argmax(prediction[0])\n",
    "confidence = prediction[0][predicted_class] * 100\n",
    "\n",
    "print(f\"Predicted class: {['rose', 'tulip', 'sunflower'][predicted_class]}\")\n",
    "print(f\"Confidence: {confidence:.2f}%\")\n",
    "print(\"Model loaded and tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated a complete machine learning workflow for flower classification:\n",
    "\n",
    "1. **Data Exploration**: Analyzed dataset structure and class distribution\n",
    "2. **Data Preprocessing**: Implemented data cleaning, augmentation, and generators\n",
    "3. **Model Architecture**: Created both custom CNN and transfer learning models\n",
    "4. **Training**: Trained models with proper callbacks and monitoring\n",
    "5. **Evaluation**: Comprehensive evaluation with metrics and visualizations\n",
    "6. **Visualization**: Feature maps and prediction visualizations\n",
    "7. **Model Export**: Saved the best performing model for production use\n",
    "\n",
    "The trained model is now ready for deployment in the Flask API server!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
